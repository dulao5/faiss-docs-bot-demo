import os
import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

api_key = os.environ.get("OPENAI_API_KEY")
if not api_key:
    st.error("Please she the system variable OPENAI_API_KEY")
    st.stop()

@st.cache_resource
def load_qa():
    embeddings = OpenAIEmbeddings()
    db = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)
    retriever = db.as_retriever(search_kwargs={"k": 3})
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    return RetrievalQA.from_chain_type(llm, retriever=retriever)

qa = load_qa()

st.title("ğŸ“š çŸ¥è¯†åº“ + LLM Web Demo")
st.write("è¾“å…¥é—®é¢˜ï¼Œæˆ‘ä¼šä»çŸ¥è¯†åº“æ£€ç´¢ä¿¡æ¯å¹¶å›ç­”ã€‚")

query = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜")
if st.button("æé—®") and query.strip():
    with st.spinner("æ­£åœ¨æ£€ç´¢å¹¶ç”Ÿæˆç­”æ¡ˆ..."):
        answer = qa.run(query)
    st.markdown(f"**å›ç­”ï¼š** {answer}")